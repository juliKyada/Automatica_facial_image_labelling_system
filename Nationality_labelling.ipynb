{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d001ee7-6648-47ff-aec1-2db9077fd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.src.legacy.saving import legacy_h5_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e50d9c-b3a7-4758-886e-726f6c73f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled: 11854, Unlabeled: 11854\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "  \n",
    "# Paths\n",
    "src_folder = r\"D:\\Automatic_Face_Labelling\\Dataset\\UTKFace\"  # where your original UTKFace images are\n",
    "labeled_folder = r\"D:\\Automatic_Face_Labelling\\Dataset\\labeled\"\n",
    "unlabeled_folder = r\"D:\\Automatic_Face_Labelling\\Dataset\\unlabeled\"\n",
    "\n",
    "os.makedirs(labeled_folder, exist_ok=True)\n",
    "os.makedirs(unlabeled_folder, exist_ok=True) \n",
    "\n",
    "# Percentage of dataset to make \"unlabeled\"\n",
    "UNLABELED_SPLIT = 0.5  # 50% unlabeled\n",
    "\n",
    "# Get all images\n",
    "images = [f for f in os.listdir(src_folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "random.shuffle(images)\n",
    "\n",
    "# Split\n",
    "split_index = int(len(images) * UNLABELED_SPLIT)\n",
    "unlabeled_imgs = images[:split_index]\n",
    "labeled_imgs = images[split_index:]\n",
    "\n",
    "# Move files\n",
    "for img in labeled_imgs:\n",
    "    shutil.copy(os.path.join(src_folder, img), os.path.join(labeled_folder, img))\n",
    "\n",
    "for img in unlabeled_imgs:\n",
    "    shutil.copy(os.path.join(src_folder, img), os.path.join(unlabeled_folder, img))\n",
    "\n",
    "print(f\"Labeled: {len(labeled_imgs)}, Unlabeled: {len(unlabeled_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768b3f6-7731-459d-b9c0-d1348abc3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# ====== 1. Paths ======\n",
    "labeled_dir = r\"D:\\Automatic_Face_Labelling\\Dataset\\labeled\"\n",
    "unlabeled_dir = r\"D:\\Automatic_Face_Labelling\\Dataset\\unlabeled\"\n",
    "\n",
    "# ====== 2. Load Labeled Images from UTKFace ======\n",
    "def load_utkface_images(folder, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # UTKFace format: [age]_[gender]_[race]_[date&time].jpg\n",
    "            parts = filename.split(\"_\")\n",
    "            if len(parts) < 4:  # skip malformed names\n",
    "                continue\n",
    "            race = int(parts[2])  # ethnicity is the 3rd value\n",
    "\n",
    "            # Load image\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            img = image.load_img(file_path, target_size=target_size)\n",
    "            img_array = image.img_to_array(img) / 255.0\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(race)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Skipping:\", filename, \"Error:\", e)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load labeled data\n",
    "X_labeled, y_labeled = load_utkface_images(labeled_dir, target_size=(64, 64))\n",
    "\n",
    "# ====== 3. Load Unlabeled Images (no labels) ======\n",
    "def load_images_unlabeled(folder, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        img = image.load_img(file_path, target_size=target_size)\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "X_unlabeled = load_images_unlabeled(unlabeled_dir, target_size=(64, 64))\n",
    "\n",
    "print(\"Labeled images shape:\", X_labeled.shape)\n",
    "print(\"Labeled ethnicity labels shape:\", y_labeled.shape)\n",
    "print(\"Unique ethnicity labels:\", np.unique(y_labeled))\n",
    "print(\"Unlabeled images shape:\", X_unlabeled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800c760-f4e3-469a-bf14-b15e985bb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_ethnicity_image(img):\n",
    "  \n",
    "    img = cv2.resize(img, (128, 128))\n",
    " \n",
    "    return img\n",
    "\n",
    "# Preprocess your dataset\n",
    "X_unlabeled_ethnicity = np.array([preprocess_ethnicity_image(img) for img in X_unlabeled])\n",
    "X_labeled_ethnicity = np.array([preprocess_ethnicity_image(img) for img in X_labeled])\n",
    "\n",
    "# Visualization\n",
    "def visualize_ethnicity_images(images, num=10):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num):\n",
    "        plt.subplot(2, num//2, i+1)\n",
    "        img = images[i]\n",
    "        plt.imshow(img)   # Already RGB + normalized\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Image {i}\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "visualize_ethnicity_images(X_unlabeled_ethnicity, num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35028669-e4a2-4146-bc65-1151e8e9ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load your pre-trained models\n",
    "\n",
    "ethnicity_model = load_model(r\"D:\\Automatic_Face_Labelling\\models\\nationality_model.h5\")\n",
    "\n",
    "ethnicity_preds = ethnicity_model.predict(X_unlabeled_ethnicity)\n",
    "\n",
    "ethnicity_pseudo = np.argmax(ethnicity_preds, axis=1)\n",
    "\n",
    "\n",
    "print(\"Pseudo labels generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c14df1-6a84-4138-bc19-abdc2c3f4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_images_with_ethnicity(images, ethnicity_preds, num=10, class_names=None):\n",
    "    preds = np.argmax(ethnicity_preds, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(num):\n",
    "        idx = np.random.randint(0, len(images))\n",
    "        img = images[idx]\n",
    "\n",
    "        # Convert to 0â€“255 range for display\n",
    "        disp_img = (img * 255).astype(\"uint8\")\n",
    "\n",
    "        label = preds[idx]\n",
    "        title = f\"Pred: {label}\"\n",
    "        if class_names is not None and label < len(class_names):\n",
    "            title = f\"Pred: {class_names[label]}\"\n",
    "\n",
    "        plt.subplot(2, num//2, i+1)\n",
    "        plt.imshow(disp_img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d6eee-3442-4502-802c-c1c62f0f443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you have ethnicity_preds from your model\n",
    "class_names = [\"African\", \"American\", \"Asian\", \"Indian\", \"Others\"]  # adjust to your dataset\n",
    "\n",
    "display_images_with_ethnicity(X_unlabeled_ethnicity, ethnicity_preds, num=10, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d97980-4673-4b4b-9c70-0d94f4e73c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences = np.max(ethnicity_preds, axis=1)\n",
    "mask = confidences > 0.8\n",
    "\n",
    "X_confident = X_unlabeled_ethnicity[mask]\n",
    "y_confident = ethnicity_pseudo[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528d8c3-a9a3-4008-87d2-f1bd655366fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine labeled and pseudo-labeled data\n",
    "X_combined = np.concatenate([X_labeled_ethnicity, X_confident], axis=0)\n",
    "y_combined = np.concatenate([y_labeled, ethnicity_pseudo], axis=0)\n",
    "\n",
    "print(\"Final dataset shape:\", X_combined.shape, y_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86873c-9fb0-4944-9c62-f9a28a967561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images:\", X_combined.shape)\n",
    "print(\"Labels:\", y_combined.shape)\n",
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(X_combined), len(y_combined))\n",
    "X_combined = X_combined[:min_len]\n",
    "y_combined = y_combined[:min_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33779044-f009-44d8-b0ef-cf0b14541e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Suppose you have these\n",
    "# labeled_img : numpy array of shape (N, 128, 128, 3)\n",
    "# labels      : numpy array of shape (N,)   # ethnicity class labels\n",
    "\n",
    "# Split into training (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X_combined, y_combined,\n",
    "    test_size=0.2, random_state=42, stratify=y_combined  # stratify keeps class balance\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58bef6-151d-4302-be36-6c52a67e1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "# One-hot encode labels if using categorical crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(np.unique(y_combined))  # number of ethnicity classes\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test  = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfda39-548a-475e-9b04-16e8ea90219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "ethnicity_model = load_model(\"Ethnicity_lebelling.h5\")\n",
    "ethnicity_model.compile(optimizer=Adam(1e-4),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = ethnicity_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadd9f5-d9ed-42b0-91f1-4dbb226e981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ethnicity_model.save(\"Ethnicity_lebelling.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
